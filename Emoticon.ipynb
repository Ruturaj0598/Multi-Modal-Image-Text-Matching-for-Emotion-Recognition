{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMOTICDataset(Dataset):\n",
    "    def __init__(self, csv_path, npy_folder, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_path)\n",
    "        self.npy_folder = npy_folder\n",
    "        self.transform = transform\n",
    "        self.categories = [\n",
    "            'Peace', 'Affection', 'Esteem', 'Anticipation', 'Engagement', 'Confidence', \n",
    "            'Happiness', 'Pleasure', 'Excitement', 'Surprise', 'Sympathy', 'Doubt/Confusion',\n",
    "            'Disconnection', 'Fatigue', 'Embarrassment', 'Yearning', 'Disapproval', 'Aversion',\n",
    "            'Annoyance', 'Anger', 'Sensitivity', 'Sadness', 'Disquietment', 'Fear', 'Pain', 'Suffering'\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.annotations.iloc[idx]\n",
    "        img_array = np.load(f\"{self.npy_folder}/{row['Arr_name']}\")\n",
    "        img_tensor = torch.tensor(img_array, dtype=torch.float32).permute(2, 0, 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        labels = torch.tensor(row[self.categories].values.astype(float), dtype=torch.float32)\n",
    "        text = row['Filename']\n",
    "\n",
    "        return {\n",
    "            'image': img_tensor,\n",
    "            'text': text,\n",
    "            'labels': labels\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.img_encoder = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-1])\n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(2048 + 768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_input, text_input):\n",
    "        img_features = self.img_encoder(img_input).squeeze()\n",
    "        text_features = self.text_encoder(**text_input).last_hidden_state.mean(dim=1)\n",
    "        combined = torch.cat((img_features, text_features), dim=1)\n",
    "        return self.fusion(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = model.text_tokenizer(\n",
    "                batch['text'], \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = model(images, text_inputs)\n",
    "            loss = criterion(outputs, batch['labels'].to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}')\n",
    "        \n",
    "        if val_loader:\n",
    "            validate_model(model, val_loader)\n",
    "\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = model.text_tokenizer(\n",
    "                batch['text'], \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = torch.sigmoid(model(images, text_inputs))\n",
    "            preds = (outputs > 0.5).float().cpu()\n",
    "            labels = batch['labels'].cpu()\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='samples')\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown mat file type, version 115, 115",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     image_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      4\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m      5\u001b[0m     ])\n\u001b[1;32m----> 7\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m NPYMultiModalDataset(\n\u001b[0;32m      8\u001b[0m         npy_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m         mat_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m         split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m         transform\u001b[38;5;241m=\u001b[39mimage_transform\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m NPYMultiModalDataset(\n\u001b[0;32m     15\u001b[0m         npy_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m         mat_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m         split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m         transform\u001b[38;5;241m=\u001b[39mimage_transform\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     21\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m, in \u001b[0;36mNPYMultiModalDataset.__init__\u001b[1;34m(self, npy_folder, mat_path, split, transform)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, npy_folder, mat_path, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 3\u001b[0m     mat_data \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(mat_path)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations \u001b[38;5;241m=\u001b[39m mat_data[split][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m entries from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m split\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:226\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:74\u001b[0m, in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mCreate reader for matlab .mat format files.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m byte_stream, file_opened \u001b[38;5;241m=\u001b[39m _open_file(file_name, appendmat)\n\u001b[1;32m---> 74\u001b[0m mjv, mnv \u001b[38;5;241m=\u001b[39m _get_matfile_version(byte_stream)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mjv \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatFile4Reader(byte_stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), file_opened\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_miobase.py:249\u001b[0m, in \u001b[0;36m_get_matfile_version\u001b[1;34m(fileobj)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maj_val \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown mat file type, version \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mret))\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown mat file type, version 115, 115"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = NPYMultiModalDataset(\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        mat_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv',\n",
    "        split='train',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = NPYMultiModalDataset(\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        mat_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv',\n",
    "        split='val',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = MultiModalNet(num_classes=26)\n",
    "    train_model(model, train_loader, val_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = EMOTICDataset(\n",
    "        csv_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv',\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = EMOTICDataset(\n",
    "        csv_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_val.csv',\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = MultiModalNet(num_classes=26)\n",
    "    train_model(model, train_loader, val_loader, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
