{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMOTICDataset(Dataset):\n",
    "    def __init__(self, csv_path, npy_folder, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_path)\n",
    "        self.npy_folder = npy_folder\n",
    "        self.transform = transform\n",
    "        self.categories = [\n",
    "            'Peace', 'Affection', 'Esteem', 'Anticipation', 'Engagement', 'Confidence', \n",
    "            'Happiness', 'Pleasure', 'Excitement', 'Surprise', 'Sympathy', 'Doubt/Confusion',\n",
    "            'Disconnection', 'Fatigue', 'Embarrassment', 'Yearning', 'Disapproval', 'Aversion',\n",
    "            'Annoyance', 'Anger', 'Sensitivity', 'Sadness', 'Disquietment', 'Fear', 'Pain', 'Suffering'\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.annotations.iloc[idx]\n",
    "        img_array = np.load(f\"{self.npy_folder}/{row['Arr_name']}\")\n",
    "        img_tensor = torch.tensor(img_array, dtype=torch.float32).permute(2, 0, 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        labels = torch.tensor(row[self.categories].values.astype(float), dtype=torch.float32)\n",
    "        text = row['Filename']\n",
    "\n",
    "        return {\n",
    "            'image': img_tensor,\n",
    "            'text': text,\n",
    "            'labels': labels\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.img_encoder = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-1])\n",
    "        self.text_encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(2048 + 768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_input, text_input):\n",
    "        img_features = self.img_encoder(img_input).squeeze()\n",
    "        text_features = self.text_encoder(**text_input).last_hidden_state.mean(dim=1)\n",
    "        combined = torch.cat((img_features, text_features), dim=1)\n",
    "        return self.fusion(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = model.text_tokenizer(\n",
    "                batch['text'], \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = model(images, text_inputs)\n",
    "            loss = criterion(outputs, batch['labels'].to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}')\n",
    "        \n",
    "        if val_loader:\n",
    "            validate_model(model, val_loader)\n",
    "\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            text_inputs = model.text_tokenizer(\n",
    "                batch['text'], \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = torch.sigmoid(model(images, text_inputs))\n",
    "            preds = (outputs > 0.5).float().cpu()\n",
    "            labels = batch['labels'].cpu()\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='samples')\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = EMOTICDataset(\n",
    "        csv_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_train.csv',\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = EMOTICDataset(\n",
    "        csv_path='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/annots_arrs/annot_arrs_val.csv',\n",
    "        npy_folder='D:/Ruturaj/New folder (3)/Ruturaj/Smart Systems/MANAV Experiment/img_arrs',\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = MultiModalNet(num_classes=26)\n",
    "    train_model(model, train_loader, val_loader, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
